---
title: OpenHuman HLD
---

# OpenHuman High-Level Design

```mermaid
flowchart LR
  C[Candidate] --> WEB[Interview Web: Browser and WebRTC]
  INT[Interviewer/Recruiter] --> STUDIO[Studio UI: Question bank and rubric]

  WEB --> GW[OpenHuman Gateway API: Auth and session]
  STUDIO --> GW

  GW --> ORCH[Interview Orchestrator: state machine]
  ORCH --> BUS[Service Bus: events and commands]
  ORCH --> DB[(PostgreSQL)]
  ORCH --> CACHE[(Redis)]
  ORCH --> BLOB[(Blob Storage: audio and transcripts)]

  ORCH --> STT[Speech-to-Text: Azure Speech]
  ORCH --> LLM[LLM Runtime: Azure OpenAI]
  ORCH --> RAG[RAG Knowledge: Azure AI Search]

  ORCH --> HUM[HUMINEX API: ATS and onboarding]

  ORCH --> OTEL[OpenTelemetry]
  OTEL --> LAW[Log Analytics]
  OTEL --> APPI[Application Insights]
```

## Recommended AI stack (enterprise-grade)

- **Primary LLM provider**: Azure OpenAI (tenant-safe, private networking options, enterprise auth).
- **Models (recommended)**:
  - A "flagship" reasoning/chat model for interviewer agent + evaluation.
  - A smaller/faster model for classification, routing, redaction, and guardrails.
  - Optional realtime-capable model for low-latency interview interactions.
- **Agent runtime**:
  - Use a deterministic **workflow/orchestrator** for interview state (timeouts, retries, idempotency).
  - Keep LLM calls as tools invoked by the orchestrator, never as the source-of-truth state.
- **Safety**:
  - PII redaction before long-term storage, prompt/response logging with policy controls, strict RBAC.
